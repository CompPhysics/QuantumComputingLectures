TITLE: Quantum Computing Lectures for  Nano and Quantum Workshop
AUTHOR: Morten Hjorth-Jensen {copyright, 1999-present|CC BY-NC} at Department of Physics and Center for Computing in Science Education, University of Oslo, Norway & Department of Physics and Astronomy and Facility for Rare Isotope Beams, Michigan State University, East Lansing, Michigan, USA
DATE: Cali, Colombia, December 4-8, 2023




!split
===== Overview of second lecture =====

!bblock Simple Hamiltonians
  o Mathematical notation, Hilbert spaces and operators
  o Description of Quantum Systems and one-qubit systems 
  o States in Hilbert Space, pure and mixed states
  o Operators and gates
  o Density matrices
  o Simple Hamiltonians
!eblock




	
!split
===== Unitarity =====

The matrices we introduced here are so-called unitary matrices. This
is an important element in quantum mechanics since the evolution of a
closed quantum system is described by operations involving unitary
operations only.

We have defined a new state $\vert \psi_p\rangle$ as a linear expansion in terms of an orthogonal and normalized basis (our computational basis) $\phi_{\lambda}$
!bt
\begin{equation}
\vert \psi_i\rangle = \sum_{j} u_{ij}\vert \phi_{j}\rangle.
\end{equation}
!et


It is normal to choose a basis defined as the eigenfunctions of parts
of the full Hamiltonian. The typical situation consists of the
solutions of the one-body part of the Hamiltonian, that is we have

!bt
\[
\hat{h}_0\vert \phi_{i}\rangle=\epsilon_{i}\vert \phi_{i}\rangle.
\]
!et 

This is normally referred to as a single-particle basis $\vert\phi_{i}(\mathbf{r})\rangle$,
defined by the quantum numbers $i$ and $\mathbf{r}$.

!split
===== Properties of unitary transformations =====

A unitary transformation is important since it keeps the orthogonality.
To see this consider first a basis of vectors $\mathbf{v}_i$,
!bt
\[
\mathbf{v}_i = \begin{bmatrix} v_{i1} \\ \dots \\ \dots \\v_{in} \end{bmatrix}
\]
!et
We assume that the basis is orthogonal, that is 
!bt
\[
\mathbf{v}_j^T\mathbf{v}_i = \delta_{ij}.
\]
!et
An orthogonal or unitary transformation
!bt
\[
\mathbf{w}_i=\mathbf{U}\mathbf{v}_i,
\]
!et
preserves the dot product and orthogonality since
!bt
\[
\mathbf{w}_j^T\mathbf{w}_i=(\mathbf{U}\mathbf{v}_j)^T\mathbf{U}\mathbf{v}_i=\mathbf{v}_j^T\mathbf{U}^T\mathbf{U}\mathbf{v}_i= \mathbf{v}_j^T\mathbf{v}_i = \delta_{ij}.
\]
!et

This means that if the coefficients $u_{p\lambda}$ belong to a unitary
or orthogonal transformation (using the Dirac bra-ket notation)

!bt
\[
\vert \psi_i\rangle = \sum_{j} u_{ij}\vert \phi_{j}\rangle.
\]
!et

orthogonality is preserved.


_Note also that although a basis $\left\{\vert \phi_i \rangle\right\}$ contains an infinity of states, for practical calculations we have always to make some truncations._ 

!split
===== Example =====

Assume we have two one-qubit states represented by
!bt
\[
\vert \psi \rangle = \alpha \vert 0 \rangle + \beta \vert 1\rangle=\begin{bmatrix}\alpha \\ \beta \end{bmatrix},
\]
!et
and
!bt
\[
\vert \phi \rangle = \gamma \vert 0 \rangle + \delta \vert 1\rangle=\begin{bmatrix}\gamma \\ \delta \end{bmatrix}.
\]
!et

We assume that the state $\vert \phi \rangle$ is obtained through a
unitary transformation of $\vert \psi \rangle$ through a matrix
$\bm{U}$ with its hermitian conjugate $\bm{U}^{\dagger}$ with matrix
elements $u_{ij}^{\dagger}=u_{ji}^*$ and
$\bm{I}=\bm{U}\bm{U}^{\dagger}=\bm{U}^{\dagger}\bm{U}$.

!split
===== Unitary transformations are reversible =====

Note that this means that the hermitian conjugate of a unitary matrix
is equal to its inverse. This has important consequences for what is
called reversibility. We say quantum mechanics is a theory which is
reversible with a probabilistic determinism. Classical mechanics on
the other is reversible in a deterministic way, that is, knowing all
initial conditions we can in principle determine the future motion of
an object which obey the laws of motion of classical mechanics.

We have then
!bt
\[
\begin{bmatrix}\gamma \\ \delta \end{bmatrix}=\begin{bmatrix}u_{00} & u_{01} \\ u_{10} & u_{11} \end{bmatrix}\begin{bmatrix}\alpha \\ \beta \end{bmatrix}.
\]
!et

Since our original basis $\vert \psi\rangle$ is orthogonal and normalized with $\vert\alpha\vert^2+\vert\beta\vert^2=1$, the new basis is also orthogonal and normalized, as we can see below here.

Since the inverse of a hermitian matrix is equal to its hermitian
conjugate/adjoint), unitary transformations are always reversible.

!split
===== Why are only unitary transformations allowed? =====


Why are only unitary transformations allowed? The key lies in the way the inner product tranforms.

To see this we rewrite the new basis from the previous example in its two components as
!bt
\[
\vert \phi\rangle_i=\sum_{j}u_{ij}\vert \psi\rangle_j,
\]
!et
or in terms of a matrix-vector notatio we have
!bt
\[
\vert \phi\rangle=\bm{U}\vert \psi\rangle,
\]
!et

We have already assumed that $\langle \psi \vert \psi \rangle = \vert\alpha\vert^2+\vert\beta\vert^2=1$.

We have that 
!bt
\[
\langle \phi\vert_i=\sum_{j}u_{ij}^*\langle \psi\vert_j,
\]
!et
or in terms of a matrix-vector notation we have
!bt
\[
\langle \phi\vert=\langle \psi\vert\bm{U}^{\dagger}.
\]
!et

Note that the two vectors are row vectors now.

If we stay with this notation we have

!bt
\[
\langle \phi\vert\phi\rangle = \langle \psi \bm{U}^{\dagger}\bm{U}\vert \psi\rangle = \langle \psi\vert \psi\rangle=1!
\]
!et

Unitary transformations are rotations in state space which preserve the
length (the square root of the inner product) of the state vector.


!split
===== Representation of states and Hamiltonians =====


Before we proceed we need several other definitions.  Throughout these
lectures we will assume that the interacting part of the Hamiltonian
can be approximated by a two-body interaction.  This means that our
Hamiltonian can be written as the sum of a onebody part, which
includes kinetic energy and an eventual external field, and a twobody
interaction




!bt
\begin{equation}
    \hat{H} = \hat{H}_0 + \hat{H}_I 
    = \sum_{i=1}^N \hat{h}_0(x_i) + \sum_{i < j}^N \hat{v}(r_{ij}),
\end{equation}
!et
with 
!bt
\begin{equation}
  H_0=\sum_{i=1}^N \hat{h}_0(x_i).
label{hinuclei}
\end{equation}
!et

The onebody part $u_{\mathrm{ext}}(x_i)$ is normally approximated by a
harmonic oscillator potential or the Coulomb interaction an electron
feels from the nucleus. However, other potentials are fully possible,
such as one derived from the self-consistent solution of the
Hartree-Fock equations.


!split
===== Simple  Hamiltonian models =====



In order to study get started with coding, we will study two simple Hamiltonian systems, one which we can use for a single qubit systems and one which has as basis functions a two-qubit system. These two simple Hamiltonians exhibit also something which is called level crossing, a feature which we will use in later studies of entanglement.

We study first a simple two-level system. Thereafter we
extend our model to a four-level system which can be
interpreted as composed of two separate (not necesseraly identical)
subsystems.

We let our hamiltonian depend linearly on a strength parameter $z$

!bt
\[
       H=H_0+\lambda H_\mathrm{I},
\]
!et

with $\lambda \in [0,1]$, where the limits $\lambda=0$ and $\lambda=1$
represent the non-interacting (or unperturbed) and fully interacting
system, respectively.  The model is an eigenvalue problem with only
two available states, which we label $\vert 0\rangle$ and $\vert
1\rangle$, respectively. Below we will let state $\vert 0 \rangle$
represent the lowest state (often referred to as model-space state)
with its pertinent eigenvalue and eigenvector whereas state $\vert 1\rangle$ represents the eigenvalue of
the excluded space.  The non-interacting solutions to our problem are

!bt
\begin{equation}
       H_0\vert 0 \rangle =\epsilon_0\vert 0 \rangle,
\end{equation}
!et
and
!bt
\begin{equation}
       H_0\vert 1\rangle =\epsilon_1\vert 1\rangle,
\end{equation}
!et

with $\epsilon_0 < \epsilon_1$. We label the off-diagonal matrix
elements $X$, while $X_0=\langle 0 \vert H_I\vert 0 \rangle$ and
$X_1=\langle 1 \vert H_1\vert 1 \rangle$.  The exact eigenvalue
problem

!bt
label{eq:twolevelH}
\begin{equation}
\left(\begin{array}{cc}\epsilon_0+\lambda X_0 &\lambda X \\
\lambda X &\epsilon_1+\lambda X_1 \end{array}\right)
\end{equation}
!et
yields
!bt
\begin{eqnarray}
     label{eq:exact}
     E(\lambda)=&\frac{1}{2}\left\{\epsilon_0 +\epsilon_1 +\lambda X_0
     +\lambda X_1 \pm \left(
     \epsilon_1 -\epsilon_0 +\lambda X_1-\lambda X_0\right) \right. \\ \nonumber
     & \left. \times\sqrt{1+\frac{4\lambda^2X^2}{\left(
     \epsilon_1 -\epsilon_0 +\lambda X_1-\lambda X_0\right)^2}}
     \right\}.
\end{eqnarray}
!et


!split
===== Solutions =====

In the results below we set the parameters $\epsilon_0=0$,
$\epsilon_1=4$, $X_0=-X_1=3$ and $X=0.2$.  This eigenvalue problem can
easily be rewritten in terms of the standard Pauli matrices.  The
non-interacting solutions represent our computational basis.
Pertinent to our choice of parameters, is that at $\lambda\geq 2/3$,
the lowest eigenstate is dominated by $\vert 1\rangle$ while the upper
is $\vert 0 \rangle$. At $\lambda=1$ the $\vert 0 \rangle$ mixing of
the lowest eigenvalue is $1\%$ while for $\lambda\leq 2/3$ we have a
$\vert 0 \rangle$ component of more than $90\%$.  The character of the
eigenvectors has therefore been interchanged when passing $z=2/3$. The
value of the parameter $X$ represents the strength of the coupling
between the model space and the excluded space.  The following code
computes and plots the eigenvalues.

!bc pycod
%matplotlib inline

from  matplotlib import pyplot as plt
import numpy as np
dim = 2
#Setting up a tridiagonal matrix and finding eigenvectors and eigenvalues
Hamiltonian = np.zeros((dim,dim))
#number of lambda values
n = 100
lmbd = np.linspace(0.,1.0,n)
e0 = 0.0
e1 = 4.0
X = 0.20
Xp = 3.0
Eigenvalue = np.zeros((dim,n))
for i in range(n): 
    Hamiltonian[0,0] = lmbd[i]*Xp+e0
    Hamiltonian[0,1] = lmbd[i]*X
    Hamiltonian[1,0] = Hamiltonian[0,1]
    Hamiltonian[1,1] = e1+lmbd[i]*(-Xp)
    # diagonalize and obtain eigenvalues, not necessarily sorted
    EigValues, EigVectors = np.linalg.eig(Hamiltonian)
    # sort eigenvectors and eigenvalues
    permute = EigValues.argsort()
    EigValues = EigValues[permute]
    EigVectors = EigVectors[:,permute]
    Eigenvalue[0,i] = EigValues[0]
    Eigenvalue[1,i] = EigValues[1]
plt.plot(lmbd, Eigenvalue[0,:] ,'b-',lmbd, Eigenvalue[1,:],'g-',)
plt.xlabel('$\lambda$')
plt.ylabel('Eigenvalues')
plt.show()
!ec


What happens? 

This model exhibits a simple level crossing where the
composition of the final interacting states change character as we
gradually switch on the interaction.



!split
===== Four level systems =====

We extend the simple two-level system to a four level
system. This system can be thought of as composed of two subsystems
$A$ and $B$. Each subsystem has computational basis states

!bt
\[
\vert 0\rangle_{\mathrm{A,B}}=\begin{bmatrix} 1 & 0\end{bmatrix}^T \hspace{1cm} \vert 1\rangle_{\mathrm{A,B}}=\begin{bmatrix} 0 & 1\end{bmatrix}^T.
\]
!et
The subsystems could represent single particles or composite many-particle systems of a given symmetry.
This leads to the many-body computational basis states

!bt
\[
\vert 00\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 1 & 0 & 0 &0\end{bmatrix}^T,
\]
!et
and
!bt
\[
\vert 10\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 1 & 0 &0\end{bmatrix}^T,
\]
!et
and
!bt
\[
\vert 01\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 1 &0\end{bmatrix}^T,
\]
!et
and finally
!bt
\[
\vert 11\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 0 &1\end{bmatrix}^T.
\]
!et

These computational basis states define also the eigenstates of the non-interacting  Hamiltonian
!bt
\[
H_0\vert 00 \rangle = \epsilon_{00}\vert 00 \rangle,
\]
!et
!bt
\[
H_0\vert 10 \rangle = \epsilon_{10}\vert 10 \rangle,
\]
!et
!bt
\[
H_0\vert 01 \rangle = \epsilon_{01}\vert 01 \rangle,
\]
!et
and
!bt
\[
H_0\vert 11 \rangle = \epsilon_{11}\vert 11 \rangle.
\]
!et
The interacting part of the Hamiltonian $H_{\mathrm{I}}$ is given by the tensor product of two $\sigma_x$ and $\sigma_z$  matrices, respectively, that is
!bt
\[
H_{\mathrm{I}}=H_x\sigma_x\otimes\sigma_x+H_z\sigma_z\otimes\sigma_z,
\]
!et
where $H_x$ and $H_z$ are interaction strength parameters. Our final Hamiltonian matrix is given by
!bt
\[
\bm{H}=\begin{bmatrix} \epsilon_{00}+H_z & 0 & 0 & H_x \\
                       0  & \epsilon_{10}-H_z & H_x & 0 \\
		       0 & H_x & \epsilon_{01}-H_z & 0 \\
		       H_x & 0 & 0 & \epsilon_{11} +H_z \end{bmatrix}.
\] 
!et

The four eigenstates of the above Hamiltonian matrix can in turn be used to
define density matrices. As an example, the density matrix of the
first eigenstate (lowest energy $E_0$) $\Psi_0$ is

!bt
\[
\rho_0=\left(\alpha_{00}\vert 00 \rangle\langle 00\vert+\alpha_{10}\vert 10 \rangle\langle 10\vert+\alpha_{01}\vert 01 \rangle\langle 01\vert+\alpha_{11}\vert 11 \rangle\langle 11\vert\right),
\]
!et

where the coefficients $\alpha_{ij}$ are the eigenvector coefficients
resulting from the solution of the above eigenvalue problem.


!bc pycod
%matplotlib inline
from  matplotlib import pyplot as plt
import numpy as np
from scipy.linalg import logm, expm
def log2M(a): # base 2 matrix logarithm
    return logm(a)/np.log(2.0)

dim = 4
Hamiltonian = np.zeros((dim,dim))
#number of lambda values
n = 40
lmbd = np.linspace(0.0,1.0,n)
Hx = 2.0
Hz = 3.0
# Non-diagonal part as sigma_x tensor product with sigma_x
sx = np.matrix([[0,1],[1,0]])
sx2 = Hx*np.kron(sx, sx)
# Diagonal part as sigma_z tensor product with sigma_z
sz = np.matrix([[1,0],[0,-1]])
sz2 = Hz*np.kron(sz, sz)
noninteracting = [0.0, 2.5, 6.5, 7.0]
D = np.diag(noninteracting)
Eigenvalue = np.zeros((dim,n))

for i in range(n): 
    Hamiltonian = lmbd[i]*(sx2+sz2)+D
    # diagonalize and obtain eigenvalues, not necessarily sorted
    EigValues, EigVectors = np.linalg.eig(Hamiltonian)
    # sort eigenvectors and eigenvalues
    permute = EigValues.argsort()
    EigValues = EigValues[permute]
    EigVectors = EigVectors[:,permute]
    # Compute density matrix for selected system state, here ground state
    DensityMatrix = np.zeros((dim,dim))
    DensityMatrix = np.outer(EigVectors[:,0],EigVectors[:,0])
    # Plotting eigenvalues 
    Eigenvalue[0,i] = EigValues[0]
    Eigenvalue[1,i] = EigValues[1]
    Eigenvalue[2,i] = EigValues[2]
    Eigenvalue[3,i] = EigValues[3]
plt.plot(lmbd, Eigenvalue[0,:] ,'b-',lmbd, Eigenvalue[1,:],'g-',)
plt.plot(lmbd, Eigenvalue[2,:] ,'r-',lmbd, Eigenvalue[3,:],'y-',)
plt.xlabel('$\lambda$')
plt.ylabel('Eigenvalues')
plt.show()
!ec



